{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Detection Theory: Homework\n",
    "\n",
    "You've collected data in a yes-no experiment. Now we will analyze these data using signal detection theory. In our course we use the following text:\n",
    "\n",
    "Wickens, T.D. (2002). *Elementary Signal Detection Theory*. Oxford University Press.  \n",
    "\n",
    "For this homework the most relevant sections are 1.1-1.3 (p. 3-15), 2.1-2.3 (p. 17-26) and sections 3.1 (p. 39-42) and 3.3 (45-48). But you can probably use any introduction to signal detection theory instead as long as it covers the equal-variance Gaussian model and receiver operating characteristics (and they all do). Let's first establish some common notation (following Wickens) and show you how to make a nice plot that illustrates the equal-variance Gaussian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal_detection import *\n",
    "\n",
    "# the standard normal density\n",
    "def phi(x):\n",
    "    return norm.pdf(x,0,1)\n",
    "\n",
    "# the standard normal cumulative distribution function\n",
    "def Phi(x):\n",
    "    return norm.cdf(x,0,1)\n",
    "\n",
    "# the inverse of Phi\n",
    "def Z(x):\n",
    "    return norm.ppf(x,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the typical plot that you see in all the introductions to signal detection theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we abbreviate lambda to lam because lambda is a keyword in python\n",
    "d_prime = 3\n",
    "lam = 1\n",
    "plot_sdt(d_prime,lam,p=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red curve is for the probability distribution for the noise-only trials. The green curve is the probability distribution for the signal trials. Here, both are Gaussians with equal variance (this is just the simplest variant of signal detection theory). The red area gives you the probability for a false alarm and the green hatched area gives you the probability for a hit. As a warm up for the exercises and to remind you of the basic logic of signal detection theory: Play with $d'$ and $\\lambda$ and observe how the hit rate and false alarm rate change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'roc_xy' # change xy to your initials\n",
    "intensity = 20     # put in the 75%-threshold that you used in the roc experiment\n",
    "data = load_data(subject)\n",
    "df = summarize(data,p=None,intensity=intensity,mode='all')\n",
    "df = df.droplevel('intensity') # intensity is always the same anyway\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the hits h and the false alarms f\n",
    "f = df['f']\n",
    "h = df['h']\n",
    "# and the values of the prior probabilities in each condition\n",
    "p = df.index.values\n",
    "# later we'll also need the performance in each block\n",
    "pc = df['pc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Compute your sensitivity $d'$ and your response bias $\\lambda$ for each condition. Use `plot_sdt` to make a plot for each condition. Check that the hits and false alarm rates match the empirical data. What happens to the criterion $\\lambda$ as the probability *p* for the signal trials increases?\n",
    "\n",
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute d_prime_hat\n",
    "d_prime_hat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute lambda_hat\n",
    "lam_hat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Write a function `plot_roc_z` that produces a z-transformed ROC-plot for your data. Base your function on the function `plot_roc` in `signal_detection.py` (but leave out the confidence intervals). What's a good limit for the axes? Place the original ROC plot and the new z-transformed ROC plot next to each other using `subplot`.\n",
    "\n",
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_z(df, labels=True, color='tab:blue'):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot(1,2,1)\n",
    "plot_roc(df)\n",
    "subplot(1,2,2)\n",
    "plot_roc_z(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Assuming that your sensitivity is constant in all conditions, we can compute the average $\\hat{d'}$ across all conditions as our estimate for your sensitivity. Use this estimate to draw out the corresponding ROC-curves in both plots from the previous exercise. Are there any data points that the ROC-curve for the equal-variance Gaussian model fits better than the ROC-line that results from the assumption that the proportion of correct responses stays constant (see `signal_detection_data_collection.ipynb`)?\n",
    "\n",
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average over all d_prime_hat in all conditions\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "From now on, we take es our \"best\" estimate for your sensitivity the average the average $\\hat{d'}$ over all conditions -- as in the last exercise. Make a plot with `plot_sdt` with this estimate for an unbiased subject. How do you have choose $\\lambda$ if you want to be unbiased? Where on the ROC-curve is the point where you're unbiased? Were you unbiased in the $p=0.5$ condition (go back to Exercise 1 to check)?\n",
    "\n",
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "How biased should you have been in each of the other conditions, where $p\\neq0.5$? Given your estimate for your sensitivity $d'$, what should your criterion $\\lambda$ have been? In order to derive and compute the optimal $\\lambda$ for a given $d'$ and $p$ you will have to use Bayes' theorem. Let $X$ be the random variable based on which you decide and $S$ is the stimulus in a trial. A useful variant of Bayes' theorem is this:\n",
    "\n",
    "$$\n",
    "\\frac{p(S=\\text{signal}\\mid X=x)}{p(S=\\text{noise}\\mid X=x)} = \\frac{p(X=x\\mid S=\\text{signal})}{p(X=x\\mid S=\\text{noise})}\\cdot\\frac{p(S=\\text{signal})}{p(S=\\text{noise})}\n",
    "$$\n",
    "\n",
    "The term on the left is called the posterior odds, the second the term is the likelihood ratio and the last term gives the prior odds. The task for this exercise is: Derive this equation from the traditional form of Bayes' theorem.\n",
    "\n",
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Obviously, you should say that you saw the stimulus whenver the posterior odds are greater than 1 because this means that it is more probable that there was a signal than that there was not. Hence, given an observation $X=x$ you should ask yourself:\n",
    "\n",
    "$$\n",
    "\\frac{p(X=x\\mid S=\\text{signal})}{p(X=x\\mid S=\\text{noise})} > \\frac{p(S=\\text{noise})}{p(S=\\text{signal})} ?\n",
    "$$\n",
    "\n",
    "Intuitively speaking, this inequality asks whether there is enough evidence of a signal in the observation $X=x$ to overrule the prior odds for there being no signal. In the equal-variance Gaussian model we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(X=x\\mid S=\\text{noise}) &= \\phi(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^2} \\\\\n",
    "p(X=x\\mid S=\\text{signal}) &= \\phi(x-d') = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(x-d')^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and just as before we will use the shorthand $p(S=\\text{signal})=p$ and correspondingly $p(S=\\text{noise})=1-p$. Plug all of these into the above equation and solve for $x$, i.e. answer the question: for which values of $x$ should you say that there was a signal? What is the optimal criterion $\\lambda$ for a given $d'$ and $p$. According to your derivation, what is the optimal criterion in the condition $p=0.5$ when you should be unbiased?\n",
    "\n",
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "\n",
    "How does the proportion of correct responses change with the criterion? For your estimate of your sensitivity make a plot of the proportion of correct responses in each condition as a function of the criterion $\\lambda$. Mark zero and $d'$ on the x-axis. Also mark the optimal $\\lambda$ on each curve as computed in Exercise 6. For $\\lambda$ on the far left and the far right, where do the error curves saturate and why? In your plots you should be able to see that the optimal $\\lambda$ really maximizes the proportion of of correct responses. How does your actual proportion of correct responses compare to the maximum proportion of correct responses we would expect based your estimated sensitivity?\n",
    "\n",
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal lambda\n",
    "lam_opt = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal proportion of correct responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed proportion of correct responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "\n",
    "Your performance was probably a little worse than it could have been. This means that you haven't set your criterion optimally. How does the measured criterion compare to the optimal criterion in each condition? Do you see systematic deviations? How would you characterize them?\n",
    "\n",
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
